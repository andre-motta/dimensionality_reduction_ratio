# DRR: Dimensionality Reduction Ratio Toolkit

[![CI](https://github.com/andre-motta/dimensionality_reduction_ratio/workflows/CI/badge.svg)](https://github.com/andre-motta/dimensionality_reduction_ratio/actions)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: Unlicense](https://img.shields.io/badge/License-Unlicense-blue.svg)](http://unlicense.org/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Coverage: 82%](https://img.shields.io/badge/coverage-82%25-brightgreen.svg)](https://github.com/andre-motta/dimensionality_reduction_ratio/actions)

> **"Less Noise, More Signal: DRR for Better Optimizations of SE Tasks"**  
> *A research-backed approach to predicting when lightweight algorithms suffice*

A professional Python toolkit for estimating intrinsic dimensionality and computing **Dimensionality Reduction Ratio (DRR)** metrics. This implementation is based on cutting-edge research from NC State University showing that **DRR can predict when simple algorithms outperform complex AI methods by orders of magnitude**.

## ğŸ¯ Research Background

This toolkit implements the methodology from our research paper ["Less Noise, More Signal: DRR for Better Optimizations of SE Tasks"](https://arxiv.org/abs/2503.21086) which demonstrates that:

- **89% of Software Engineering datasets** satisfy the DRR threshold for simplified optimization
- **Simple methods can be 100x faster** than state-of-the-art optimizers when DRR > 1/3
- **SE data has lower intrinsic complexity** (median 3.1 dimensions) compared to general ML data (median 5 dimensions)

## ğŸ”¬ What is DRR?

The **Dimensionality Reduction Ratio (DRR)** is a metric that quantifies how much dimensionality reduction is possible in a dataset:

```
DRR = 1 - (I/R)
```

Where:
- **I** = Intrinsic dimension (estimated using correlation function analysis)
- **R** = Raw dimension (number of original features)

### Research Finding: The 1/3 Threshold

Our research shows that when **DRR > 1/3**, simple algorithms can achieve the same performance as complex state-of-the-art optimizers but run **two orders of magnitude faster**.

## ğŸš€ Quick Start

```bash
# Install the package
pip install drr

# Process all datasets from configuration file
drr batch datasets.txt

# Process a single dataset
drr single data/config/Apache_AllMeasurements.csv

# Use custom parameters with debug logging
drr --log-level DEBUG batch datasets.txt --max-samples 5000 --metric euclidean
```

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Dataset Configuration](#dataset-configuration)
- [Algorithm Details](#algorithm-details)
- [DRR Metrics](#drr-metrics)
- [API Reference](#api-reference)
- [Results](#results)
- [Contributing](#contributing)

## ğŸ” Overview

This toolkit implements the **Levina-Bickel correlation function method** for intrinsic dimension estimation, enhanced with:

- **DRR (Dimensionality Reduction Ratio)** metric: `DRR = 1 - (I/R)`
- **Large dataset handling** with intelligent sampling strategies
- **Batch processing** capabilities for multiple datasets
- **Professional logging** and error handling
- **Resume functionality** for interrupted processing jobs

### What is Intrinsic Dimension?

The **intrinsic dimension** of a dataset is the minimum number of parameters needed to represent the data without significant information loss. While a dataset might exist in a high-dimensional space (raw dimension R), its true complexity might be much lower (intrinsic dimension I).

### What is DRR?

**Dimensionality Reduction Ratio (DRR)** quantifies how much dimensionality reduction is possible:
- `DRR = 1 - (I/R)`
- **High DRR (>0.5)**: Significant dimensionality reduction possible
- **Low DRR (<0.3)**: Dataset complexity is close to its raw dimensionality

## âœ¨ Features

### Core Capabilities
- ğŸ”¬ **Intrinsic dimension estimation** using correlation function analysis
- ğŸ“Š **DRR metric computation** for dataset complexity analysis
- ğŸ—‚ï¸ **Batch processing** of multiple datasets from configuration files
- ğŸ“ˆ **Large dataset optimization** with multi-level sampling
- ğŸ”§ **Resume functionality** for interrupted processing jobs

### Technical Features
- ğŸ—ï¸ **Professional architecture** with modular design
- ğŸ“ **Comprehensive logging** with configurable levels
- ğŸ›¡ï¸ **Robust error handling** and validation
- ğŸ”„ **Progress tracking** and status reporting
- ğŸ“Š **CSV results export** with detailed metrics

### Data Processing
- ğŸ§¹ **Automatic preprocessing** (categorical encoding, missing value handling)
- ğŸ¯ **Goal variable detection** and removal
- ğŸ“ **Distance metric selection** (L1, L2, Euclidean, Manhattan, Cosine)
- ğŸ”€ **Intelligent sampling** for datasets >50K rows

## ğŸ› ï¸ Installation

## ğŸ› ï¸ Installation

### From PyPI (Recommended)
```bash
# Install the latest stable version
pip install drr

# Install with development dependencies
pip install drr[dev]

# Install with all optional dependencies
pip install drr[all]
```

### From Source
```bash
# Clone the repository
git clone https://github.com/andre-motta/dimensionality_reduction_ratio.git
cd dimensionality_reduction_ratio

# Install in development mode
pip install -e .

# Or install with development dependencies
pip install -e .[dev]
```

### Prerequisites
- Python 3.11+
- pip (Python package installer)

### Verify Installation
```bash
# Test the command-line interface
drr --help

# Or if installed from source
cd src
python -m drr --help
```

### Dependencies
This project uses the following key libraries:
- **Click**: Modern command-line interface framework
- **NumPy**: Numerical computing library
- **Pandas**: Data manipulation and analysis
- **SciPy**: Scientific computing library
- **Matplotlib**: Plotting library

## ğŸ“– Usage

### Command Line Interface

#### Batch Processing
Process multiple datasets from a configuration file:
```bash
drr batch datasets.txt
```

With custom parameters:
```bash
drr --log-level DEBUG batch datasets.txt \
    --max-samples 5000 \
    --metric euclidean \
    --data-root data
```

#### Single Dataset Processing
Process an individual dataset:
```bash
drr single data/config/Apache_AllMeasurements.csv
```

With custom parameters:
```bash
drr single data/config/Apache_AllMeasurements.csv \
    --max-samples 3000 \
    --metric manhattan
```

#### Global Options
- `--log-level`: Logging level (`DEBUG`, `INFO`, `WARNING`, `ERROR`)
- `--log-file`: Optional log file path

#### Batch Command Options
- `datasets_file`: Path to configuration file listing datasets to process
- `--data-root`: Root directory for dataset files (default: `../data`)
- `--max-samples`: Maximum samples for large datasets (default: 2000)
- `--metric`: Distance metric (`l1`, `l2`, `euclidean`, `manhattan`, `cosine`)

#### Single Command Options  
- `dataset_path`: Path to the dataset file to process
- `--max-samples`: Maximum samples for large datasets (default: 2000)
- `--metric`: Distance metric (`l1`, `l2`, `euclidean`, `manhattan`, `cosine`)

### Python API

#### Single Dataset Analysis
```python
import drr

# Simple usage with convenience function
data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]  # Your dataset
original_dims, intrinsic_dim, drr_value = drr.estimate_intrinsic_dimension(data)

print(f"Raw dimensions: {original_dims}")
print(f"Intrinsic dimension: {intrinsic_dim}")
print(f"DRR: {drr_value:.3f}")

# Advanced usage with classes
estimator = drr.IntrinsicDimensionEstimator(max_samples=2000, distance_metric='euclidean')
processor = drr.DataProcessor()

# Process dataset from file
data, metadata = processor.process_dataset('data/config/Apache_AllMeasurements.csv')
original_dims, intrinsic_dim, drr_value = estimator.estimate(data)
```

#### Batch Processing
```python
import drr

# Initialize batch processor
processor = drr.BatchProcessor(
    results_file="results/my_results.csv",
    max_samples=2000,
    distance_metric='manhattan'
)

# Process all datasets
results = processor.process_datasets_from_file('datasets.txt')
print(f"Processed {results['successful']} datasets successfully")
```

## ğŸ“ Dataset Configuration

The `datasets.txt` file defines which datasets to process using a hierarchical structure:

### Format
```
# Configuration section
config
    Apache_AllMeasurements
    HSMGP_num
    SQL_AllMeasurements

# Classification datasets  
classify
    breastcancer
    diabetes
    german

# Software measurement datasets
mvn
    training_set/mvn_training
    test_set/mvn_test
```

### Rules
1. **Section headers** have no indentation
2. **Dataset names** are indented (spaces or tabs)
3. **Comments** start with `#`
4. **File paths** are relative to `data_root` directory
5. **CSV extension** is automatically added

## ğŸ”¬ Algorithm Details

### Fractal-Based Intrinsic Dimension Estimation

This toolkit implements the **correlation function method** used in our research, which leverages fractal geometry concepts to estimate intrinsic dimensionality:

1. **Distance Analysis**: Calculate pairwise distances between data points
2. **Correlation Function**: For radius R, compute `C(r) = (2 * I) / (n * (n-1))` where I is the number of pairs with distance â‰¤ r
3. **Fractal Dimension**: Analyze how the number of points scales with distance radius
4. **Gradient Analysis**: The maximum gradient of log(C(r)) vs log(r) approximates the intrinsic dimension

### Key Advantages

- **Accuracy**: More precise than traditional PCA-based methods
- **Robustness**: Less sensitive to noise and outliers  
- **Scalability**: Efficient for large datasets through intelligent sampling
- **Research-Validated**: Proven effective on 24+ real-world datasets

### The Research Breakthrough

Our methodology **fixes critical errors** in previous approaches:
- Previous work suggested simple algorithms when I < 4
- Our research found **many counter-examples** to this threshold
- **New threshold: DRR > 1/3** provides much more accurate predictions

## ğŸ“Š DRR Metrics & Research Insights

### Understanding DRR Values

**DRR = 1 - (I/R)** where:
- **I**: Intrinsic dimension (estimated)
- **R**: Raw dimension (number of features)
- **DRR**: Dimensionality Reduction Ratio

### Research-Based Interpretation Guidelines

| DRR Range | Algorithm Recommendation | Performance Insight | SE Data Examples |
|-----------|--------------------------|---------------------|------------------|
| **> 0.67** | Use simple methods | 100x faster, same quality | Software configuration (SS-B, SS-D) |
| **0.33 - 0.67** | Simple methods often sufficient | 10-50x speedup possible | Most SE optimization tasks |
| **< 0.33** | Complex methods may be needed | Intrinsic complexity requires sophisticated algorithms | General ML datasets |

### Key Research Findings

ğŸ“ˆ **SE vs General ML Data**:
- **Median SE intrinsic dimensionality**: 3.1 dimensions
- **Median general ML intrinsic dimensionality**: 5.0 dimensions  
- **Conclusion**: SE problems are inherently less complex

ğŸš€ **Performance Implications**:
- **89% of SE datasets** satisfy DRR > 1/3 threshold
- **Simple algorithms** (30 samples) perform as well as complex ones (3000 samples)
- **Speedup**: 2 orders of magnitude (seconds vs 20 minutes)

## ğŸ“ˆ Results

### Sample Output

```
===============================================
RESULTS FOR: Apache_AllMeasurements.csv
===============================================
Original Dimensions (R): 43
Intrinsic Dimension (I): 12
DRR (1 - I/R): 0.721
Data Quality: 72.1% dimensionality reduction
===============================================
```

## ğŸ—‚ï¸ Directory Structure

```
dimensionality_reduction_ratio/
â”œâ”€â”€ src/                      # Source code modules
â”‚   â”œâ”€â”€ main.py              # Command-line entry point
â”‚   â”œâ”€â”€ intrinsic_dimension.py  # Core algorithm
â”‚   â”œâ”€â”€ data_processor.py    # Data preprocessing
â”‚   â””â”€â”€ batch_processor.py   # Batch processing
â”œâ”€â”€ config/                   # Configuration files
â”‚   â”œâ”€â”€ datasets.txt         # Dataset configuration
â”‚   â””â”€â”€ test_datasets.txt    # Test configuration
â”œâ”€â”€ data/                     # Dataset files
â”œâ”€â”€ results/                  # Output files
â”œâ”€â”€ logs/                     # Log files
â”œâ”€â”€ examples/                 # Usage examples
â”‚   â””â”€â”€ example_usage.py     # API usage examples
â””â”€â”€ README.md                # This documentation
```

## ğŸ§ª Testing

### Validate Installation
```bash
# Test the command-line interface
drr --help
drr batch --help 
drr single --help

# Test with sample data
drr single data/optimize/config/SS-A.csv

# Test batch processing (small subset)
drr batch config/test_dataset.txt
```

---

## ï¿½ Citation

If you use this toolkit in your research, please cite our paper:

```bibtex
@article{lustosa2025drr,
  title={Less Noise, More Signal: DRR for Better Optimizations of SE Tasks},
  author={Andre Lustosa and Tim Menzies},
  journal={arXiv preprint arXiv:2503.21086},
  year={2025},
  url={https://arxiv.org/abs/2503.21086}
}
```

## ï¿½ğŸ”— Research Links

- **ğŸ“„ Paper**: [arXiv:2503.21086](https://arxiv.org/abs/2503.21086)
- **ğŸ’» Research Code**: [GitHub Repository](https://github.com/andre-motta/dimensionality_reduction_ratio)
- **ğŸ›ï¸ Institution**: North Carolina State University, Department of Computer Science
- **ğŸ‘¥ Authors**: Andre Lustosa, Tim Menzies (Fellow, IEEE)

## ğŸ”— Repository

**GitHub Repository**: https://github.com/andre-motta/dimensionality_reduction_ratio

For questions, issues, or contributions, please visit the repository or contact the maintainers.